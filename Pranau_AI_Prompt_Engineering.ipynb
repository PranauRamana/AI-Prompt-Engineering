{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install OpenAI"
      ],
      "metadata": {
        "id": "Q-FahykNwxSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4QJ28xQw56Z",
        "outputId": "50b43d83-e8f7-4f9e-db66-840255e708ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load your API Key"
      ],
      "metadata": {
        "id": "2ioGIJZPxDxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se ur open ai API key\n",
        "\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "5pD45k8XxGl7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Prompt"
      ],
      "metadata": {
        "id": "3xuB-kT9xgPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Prompt = \"What is the capital of india ?\"\n",
        "\n",
        "# Give me 2 random facts about india"
      ],
      "metadata": {
        "id": "QMPC3G2fxiHw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Send the prompt to open API Model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "30tfvJ4Cx6V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the prompt\n",
        "messages = [{\"role\": \"user\", \"content\" :Prompt}]\n",
        "\n",
        "# Send the prompt\n",
        "response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                        messages=messages,\n",
        "                                        temperature=0.4,\n",
        "                                        n = 3)"
      ],
      "metadata": {
        "id": "m1drL7flx-WG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process the response from Open AI model"
      ],
      "metadata": {
        "id": "MtkakW1vyswB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[2].message[\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm53Ry-2yuGQ",
        "outputId": "db984c71-2d99-4abe-e514-0f4d9cec8760"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of India is New Delhi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TANGLISH TO TAMIL"
      ],
      "metadata": {
        "id": "7vpQcLlCza5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the context"
      ],
      "metadata": {
        "id": "KWUbuNzHy7ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = f\"\"\"\n",
        "You are a tanglish expert. Provide response to input text. \\\n",
        "Use tamil font in your response.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JkdFdcREy8ZJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create your prompt"
      ],
      "metadata": {
        "id": "OaLXQwdJzCKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt = f\"\"\"\n",
        "#Hey en peru Viz. Un peru enna?\n",
        "#\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Naan saapten... nee saaptiya?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uxnuPRprzDXi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the context and prompt"
      ],
      "metadata": {
        "id": "2UHciXUMzGia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\" : \"system\", \"content\" : context},\n",
        "    {\"role\" : \"user\", \"content\" : prompt}\n",
        "]"
      ],
      "metadata": {
        "id": "tcWGA12nzI3y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Send the prompt and context to Open AI Model"
      ],
      "metadata": {
        "id": "BWO3E2QHzMuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Send the prompt\n",
        "response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                        messages=messages,\n",
        "                                        temperature=0)\n",
        ""
      ],
      "metadata": {
        "id": "WoHezUE6zO2i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process the response from Open AI model"
      ],
      "metadata": {
        "id": "FTEl70YEzTdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message[\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyvz0ZJnzUxS",
        "outputId": "ccf41dc8-a446-4a0c-ba7b-238c5aa4c2f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ஆமாம், நானும் சாப்பிட்டேன். நீங்களும் சாப்பிட்டீர்களா?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the context as Tanglish Expert"
      ],
      "metadata": {
        "id": "LA0wP2Rhzu3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = f\"\"\"\n",
        "You are a tanglish expert. You can understand and process tanglish language \\\n",
        "and capable of producing output response in tanglish language\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mloxkf-RzwHI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper Function to send & display"
      ],
      "metadata": {
        "id": "0IrjSYcqz4uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "def serveAndDisplay():\n",
        "  # Send the prompt\n",
        "  response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                        messages=messages,\n",
        "                                        temperature=0.7)\n",
        "  display(HTML(response.choices[0].message[\"content\"]))"
      ],
      "metadata": {
        "id": "DtgD6E37z5bn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 Types of Using OpenAI Model"
      ],
      "metadata": {
        "id": "HZXVqyKGz9cy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Summarization (சுருக்கமாகக் கூறு)"
      ],
      "metadata": {
        "id": "M6Am5CUq0B0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Summarize the input text not more than 3 lines.\n",
        "\n",
        "input text: Ponniyin Selvan padam ippo than pathutu vanthen. \\\n",
        "Padam super huh irukku. Both part1 and part2 padam nalla \\\n",
        "irukku. padathoda music um super huh than irukku. rombha nalla padam.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "soHwFSLF0C_6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\" : \"system\", \"content\" : context},\n",
        "    {\"role\" : \"user\", \"content\" : prompt}\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "DvV-_rVl0GAM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serveAndDisplay()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "IobB9JD00Kpf",
        "outputId": "786c4187-9be6-4b3b-d7b1-8f75c4b71c34"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ponniyin Selvan movie pathutu vanthen. Padam super huh iruku, part1 and part2 padam nalla irukku. Musicum super huh iruku, rombha nalla padam."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Inference (உட்கருத்து உணர்தல்)"
      ],
      "metadata": {
        "id": "yzGDVCyZ0OPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "What is the overall sentiment of the input text? \\\n",
        "Give your answer as a single word, either \"positive\" \\\n",
        "or \"negative\".\n",
        "\n",
        "input text: Ponniyin Selvan padam ippo than pathutu vanthen. \\\n",
        "Padam super huh irukku. Both part1 and part2 padam nalla \\\n",
        "irukku. padathoda music um super huh than irukku. rombha nalla padam.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "R2cM5I6U0PB1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\" : \"system\", \"content\" : context},\n",
        "    {\"role\" : \"user\", \"content\" : prompt}\n",
        "]\n",
        ""
      ],
      "metadata": {
        "id": "E-qNKiCj0RdQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serveAndDisplay()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "JwLiZ5CR0WPN",
        "outputId": "f6d3e7b9-556f-445e-899d-e8adc9d7ecb0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "positive"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Expand (விரிவுபடுத்துதல்)"
      ],
      "metadata": {
        "id": "NoJxoZW20Ymo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "review = f\"\"\"\n",
        "Generally Intha hotel la masala dosa rombha nalla irukkum. \\\n",
        "Athuvum ghee masala dosa ennoda favorite. \\\n",
        "But konja naala taste bad huh irukku. Also it is very expensive. \\\n",
        "Not worth the amount spent in my opinion. Parking vasathi nalla irukku. \\\n",
        "\"\"\"\n",
        "\n",
        "review2 = f\"\"\"\n",
        "Ithu oru nalla pure veg restaurant. \\\n",
        "Especially set dosa with vada curry rombha super. \\\n",
        "Service prompt huh illa and menu card kooda avanga tharala. \\\n",
        "Waiting period was there and rombha crowded huh irunthuchi.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Your task is to send an email reply to a valued customer.\n",
        "Given the customer review delimited by ```, \\\n",
        "Generate a reply to thank the customer for their review.\n",
        "If the sentiment is positive or neutral, thank them for \\\n",
        "their review.\n",
        "If the sentiment is negative, apologize and suggest that \\\n",
        "they can reach out to customer service.\n",
        "Make sure to use specific details from the review.\n",
        "Write in a concise and professional tone.\n",
        "Sign the email as `AI customer agent`.\n",
        "Provide your response in tanglish language only\n",
        "Customer review: ```{review}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Hwa9j9pL0Z0H"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = f\"\"\"\n",
        "You are a customer service AI assistant and also a tanglish expert. \\\n",
        "You can understand and process tanglish language \\\n",
        "and capable of producing output response in tanglish language.\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\" : \"system\", \"content\" : context},\n",
        "    {\"role\" : \"user\", \"content\" : prompt}\n",
        "]\n",
        ""
      ],
      "metadata": {
        "id": "P8Y4SA6y0duY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serveAndDisplay()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "PpEamt1U0g44",
        "outputId": "40da96a6-f0e7-4dac-cd66-8f9ac8f9e17d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Formal English (Medieval style):\n",
              "Verily, I cannot arrive on the morrow. Pray, may I come hither today instead?\n",
              "\n",
              "Modern Texas Cowboy Accent Style:\n",
              "Ah reckon I can't make it tomorrow, partner. Kin I come on down today 'stead?"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Translation (மொழி மாற்றம்)"
      ],
      "metadata": {
        "id": "0V6ozt5t0jI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You are a universal translator. Translate the input text as follows \\\n",
        "- coimbatore tanglish\n",
        "- Formal english using medieval style\n",
        "- Modern texas cowboy accent style\n",
        "\n",
        "text : I cannot come tomorrow. Can I come today instead?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_mZSNXiN0j_s"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\" : \"user\", \"content\" : prompt}\n",
        "]"
      ],
      "metadata": {
        "id": "JxGVK0GM0nHz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serveAndDisplay()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "HnpEAgE_0u5d",
        "outputId": "e391e8bf-9536-4334-a410-966f6e2b386a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Formal english using medieval style:\n",
              "Verily, I cannot make my way hither on the morrow. Pray, may I make my way hither today instead?\n",
              "\n",
              "Modern texas cowboy accent style:\n",
              "Ah reckon I can't make it tomorrow, pardner. Can I mosey on over today instead?"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}